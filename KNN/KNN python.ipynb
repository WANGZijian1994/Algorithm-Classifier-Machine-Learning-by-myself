{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "### Author : Zijian\n",
    "\n",
    "\n",
    "### To normalize the data: to change the values of numeric columns in the dataset to a common scale, \n",
    "### without distorting differences in the ranges of values\n",
    "def Normalization(l):\n",
    "    Max = max(l)\n",
    "    Min = min(l)\n",
    "    res = [(x-Min)/(Max-Min) for x in l]\n",
    "    return res\n",
    "\n",
    "### KNN classifer, you can change the value of parameter K as you wish, and you could also decide whether do the normalization or not;\n",
    "def KNN_Zijian(test_data,value_data,group_name,k=5,Normalise = True):\n",
    "    test_data = [list(x) for x in test_data]\n",
    "    value_data = [list(value_data[i]) for i in range(len(value_data))]\n",
    "    group_name = list(group_name)\n",
    "    if Normalise:\n",
    "        value_data = [Normalization(x) for x in value_data]  \n",
    "        test_data = [Normalization(x) for x in test_data]\n",
    "    distance = []\n",
    "    for i in range(len(value_data)):\n",
    "        diff = float()\n",
    "        for j in range(len(value_data[i])):\n",
    "            diff += abs(test_data[i][j]-value_data[i][j])**2 ### using euclidien distance for every group of test data/\n",
    "        diff = diff**(0.5)\n",
    "        feature = group_name[i]\n",
    "        distance.append([diff,feature])\n",
    "    ### find the most relevant feature between the k nearnest neighbor\n",
    "    distance.sort()\n",
    "    candidat = [x[1] for x in distance[:k]]\n",
    "    res = {}\n",
    "    for x in candidat:\n",
    "        res[x]=res.get(x,0)+1\n",
    "    Max = 0\n",
    "    result = \"\"\n",
    "    for x,y in res.items():\n",
    "        if y>Max:\n",
    "            Max = y\n",
    "            result = x\n",
    "    return result\n",
    "\n",
    "### get the value classified by kNN for every element in the test data and get the result.\n",
    "def KNN_fit(x_test,x_train,y_train,k=5,Normalization=True):\n",
    "    result = []\n",
    "    for x in x_test:\n",
    "        test = [x for i in range(x_train.shape[0])]\n",
    "        result.append(KNN_Zijian(test,x_train,y_train,k,Normalization))\n",
    "    return result\n",
    "\n",
    "def score(result,y_test):\n",
    "    correct = 0\n",
    "    taille = len(result)\n",
    "    for i in range(taille):\n",
    "        if result[i]==y_test[i]:\n",
    "            correct+=1\n",
    "    return str(correct/taille * 100)+\"%\"\n",
    "\n",
    "### ---- Test with Iris data in Sklearn dataset\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_iris()\n",
    "x_data = data.data\n",
    "y_data = data.target\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x_data,y_data,test_size = 0.2,random_state=0) ### 80% train 20% test\n",
    "\n",
    "result = KNN_fit(X_test,X_train,Y_train,k=5,Normalization = False)\n",
    "score_final = score(result,Y_test)\n",
    "print(score_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
